{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMSC 35300 Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv('ml-25m/ratings.csv')\n",
    "df = df.drop('timestamp', axis=1)\n",
    "df.loc[:,'rating'] *= 2  # make the ratings into an integer value\n",
    "df = df.astype(int)\n",
    "\n",
    "max_userId = df.max().loc['userId']\n",
    "max_movieId = df.max().loc['movieId']\n",
    "observation_number = df.index[-1]+1\n",
    "\n",
    "observed_data = df.to_numpy()\n",
    "observed_data[:,:-1] = observed_data[:,:-1] -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def power_factorization(n, X0, Y0, t_set, k, lambd, N):\n",
    "    slices = observation_number//N\n",
    "    \n",
    "    X = X0\n",
    "    Y = Y0\n",
    "    X1 = np.zeros((k,max_userId))\n",
    "    Y1 = np.zeros((k,max_movieId))\n",
    "    \n",
    "    startTime = time.time()\n",
    "\n",
    "    iteration = 0\n",
    "    # print('Current inner-iteration: ' + str(iteration))\n",
    "    # print('np.linalg.norm(X1-X) = ' + str(np.linalg.norm(X1-X)))\n",
    "    # print('np.linalg.norm(Y1-Y) = ' + str(np.linalg.norm(Y1-Y))+'\\n')\n",
    "\n",
    "    Xnorm_diff = np.linalg.norm(X1-X)\n",
    "    Ynorm_diff = np.linalg.norm(Y1-Y)\n",
    "\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        # print('Current inner-iteration: ' + str(iteration))\n",
    "\n",
    "\n",
    "        u_to_sums = {}\n",
    "        for s in range(slices):\n",
    "            u, i, r = t_set[s,:]\n",
    "            if u not in u_to_sums.keys():\n",
    "                u_to_sums[u] = {'sum_yi_yiT':np.zeros((k,k)), 'sum_rui_yi':np.zeros((k,1))}\n",
    "            u_to_sums[u]['sum_yi_yiT'] += Y[:,i:i+1]@Y[:,i:i+1].T\n",
    "            u_to_sums[u]['sum_rui_yi'] += r*Y[:,i:i+1]\n",
    "        for u in u_to_sums.keys():\n",
    "            X1[:,u:u+1] = np.linalg.inv(u_to_sums[u]['sum_yi_yiT']+lambd*np.diag(np.ones(k)))@u_to_sums[u]['sum_rui_yi']\n",
    "\n",
    "        executionTime = (time.time() - startTime)\n",
    "        # print('Elapsed time in seconds: ' + str(executionTime))\n",
    "\n",
    "        Xnorm_diff = np.linalg.norm(X1-X)\n",
    "        # print('np.linalg.norm(X1-X) = ' + str(Xnorm_diff)+'\\n')\n",
    "\n",
    "        if Xnorm_diff<1e-5 and Ynorm_diff<1e-5:\n",
    "            break\n",
    "\n",
    "        X = X1\n",
    "\n",
    "\n",
    "        i_to_sums = {}\n",
    "        for s in range(slices):\n",
    "            u, i, r = t_set[s,:]\n",
    "            if i not in i_to_sums.keys():\n",
    "                i_to_sums[i] = {'sum_xu_xuT': np.zeros((k,k)), 'sum_rui_xu': np.zeros((k,1))}\n",
    "            i_to_sums[i]['sum_xu_xuT'] += X[:,u:u+1]@X[:,u:u+1].T\n",
    "            i_to_sums[i]['sum_rui_xu'] += r*X[:,u:u+1]\n",
    "        for i in i_to_sums.keys():\n",
    "            Y1[:,i:i+1] = np.linalg.inv(i_to_sums[i]['sum_xu_xuT']+lambd*np.diag(np.ones(k)))@i_to_sums[i]['sum_rui_xu']\n",
    "\n",
    "        executionTime = (time.time() - startTime)\n",
    "        # print('Elapsed time in seconds: ' + str(executionTime))\n",
    "\n",
    "        Ynorm_diff = np.linalg.norm(Y1-Y)\n",
    "        # print('np.linalg.norm(Y1-Y) = ' + str(Ynorm_diff)+'\\n')\n",
    "\n",
    "        if Xnorm_diff<1e-5 and Ynorm_diff<1e-5:\n",
    "            break\n",
    "\n",
    "        Y = Y1\n",
    "\n",
    "\n",
    "    executionTime = (time.time() - startTime)\n",
    "    # print('Execution time in seconds: ' + str(executionTime))\n",
    "    # print('Total inner-iterations: ' + str(iteration))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_split_sets(N):\n",
    "    startTime = time.time()\n",
    "    \n",
    "    slices = observation_number//N\n",
    "\n",
    "    split_sets = np.zeros((N,slices, 3), dtype=int)\n",
    "\n",
    "    random_indices = np.arange(observation_number)\n",
    "    np.random.shuffle(random_indices)\n",
    "    random_indices = random_indices.reshape((N,slices))\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(slices):\n",
    "            split_sets[i,j,:] = observed_data[random_indices[i,j],:]\n",
    "    \n",
    "    executionTime = (time.time() - startTime)\n",
    "    # print('Execution time in seconds: ' + str(executionTime))\n",
    "    \n",
    "    return split_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_RMS(split_sets, k, lambd, N):\n",
    "    startTime = time.time()\n",
    "\n",
    "    slices = observation_number//N\n",
    "    X0 = np.random.uniform(0,10,(k, max_userId))\n",
    "    Y0 = np.random.uniform(0,10,(k, max_movieId))\n",
    "\n",
    "    average_RMS = 0\n",
    "    for n in range(N):\n",
    "        training_set = np.zeros(((N-1)*slices,3), dtype=int)\n",
    "        test_set = np.zeros((slices,3), dtype=int)\n",
    "        temp = np.append(split_sets[:n,:,:], split_sets[n+1:,:,:],axis=0)\n",
    "        for t in range(N-1):\n",
    "            training_set[t*slices:(t+1)*slices,:] = temp[t:t+1,:,:]\n",
    "        test_set[:,:] = split_sets[n:n+1,:,:]\n",
    "\n",
    "        X, Y = power_factorization(n, X0, Y0, training_set, k, lambd, N)\n",
    "\n",
    "        sum_first_term = 0\n",
    "        for s in range(slices):\n",
    "            u, m, r = test_set[s,:]\n",
    "            sum_first_term += (r - X[:,u].T@Y[:,m])**2\n",
    "\n",
    "        # print(\"For n=\" + str(n) + \": sum_first_term + lambda*Frobenius_norm = \" + str(sum_first_term + lambd*(np.linalg.norm(X)+np.linalg.norm(Y))))\n",
    "        # print(\"RMS for n=\" + str(n) + \": \" + str(np.sqrt(sum_first_term/slices)))\n",
    "        average_RMS += np.sqrt(sum_first_term/slices)\n",
    "    average_RMS /= N\n",
    "    print(\"Average RMS for k=\" + str(k) + \", lambda=\" + str(lambd) +\": \" + str(average_RMS))\n",
    "\n",
    "    executionTime = (time.time() - startTime)\n",
    "    print('Execution time in seconds: ' + str(executionTime) + \"\\n\")\n",
    "    \n",
    "    return average_RMS, executionTime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 5\n",
    "\n",
    "kwargs_list = []\n",
    "for k in [5, 10, 15, 20, 25, 30]:\n",
    "    for lambd in [10, 100, 1000, 10000, 100000, 1000000]:\n",
    "        kwargs_list.append({'N': N, 'k': k, 'lambd': lambd})\n",
    "\n",
    "split_sets = create_split_sets(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_kwargs_list = []\n",
    "for kwargs in kwargs_list:\n",
    "    average_RMS, executionTime = calculate_average_RMS(split_sets, **kwargs)\n",
    "    kwargs['average_RMS'] = average_RMS\n",
    "    kwargs['executionTime'] = executionTime\n",
    "    new_kwargs_list.append(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_kwargs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to a JSON file\n",
    "with open(\"iterations.json\", \"w\") as outfile:\n",
    "    json.dump(new_kwargs_list, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "with open('iterations.json', 'r') as openfile:\n",
    "    # Reading from json file\n",
    "    json_object = json.load(openfile)\n",
    "\n",
    "for dic in json_object:\n",
    "    print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('X.csv', X, delimiter=',')\n",
    "# np.savetxt('Y.csv', Y, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.loadtxt('X.csv', delimiter=',')\n",
    "# Y = np.loadtxt('Y.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d9defa72c2715dab9f7f172572cd30a1ab1a2083462d32ef96aadb7c6e0c73b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
